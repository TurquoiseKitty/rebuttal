{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db8d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "import tqdm\n",
    "import six\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from helper import set_seeds\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.datasets import get_scaled_data, get_synthetic_data\n",
    "from utils.q_model_ens import QModelEns, MSEModel\n",
    "from losses import batch_qr_loss, batch_interval_loss\n",
    "import helper\n",
    "from helper import SYN_DATA, REAL_DATA\n",
    "\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"MKL_CBWR\"] = 'AUTO'\n",
    "\n",
    "results_path = helper.results_path\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "\n",
    "def get_loss_fn(loss_name):\n",
    "    if loss_name == 'batch_qr' or loss_name == 'batch_wqr':\n",
    "        fn = batch_qr_loss\n",
    "    elif loss_name == 'batch_int':\n",
    "        fn = batch_interval_loss\n",
    "    else:\n",
    "        raise ValueError('loss arg not valid')\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "def update_results_during_training(y_upper, y_lower, x, y, set_name, results_dict, alpha):\n",
    "    with torch.no_grad():\n",
    "        if len(x) == 0 or len(y) == 0:\n",
    "            return\n",
    "        y = y.reshape(-1).to(device)\n",
    "        idx = np.random.permutation(len(x))  # [:len(xx)]\n",
    "        x = x[idx].to(device)\n",
    "        quantiles = torch.Tensor([alpha / 2, 1 - alpha / 2]).to(device)\n",
    "        \n",
    "\n",
    "        if torch.is_tensor(y):\n",
    "            curr_y = y.cpu().detach().numpy()[idx]\n",
    "        else:\n",
    "            curr_y = y[idx]\n",
    "        in_the_range = ((curr_y >= y_lower) & (curr_y <= y_upper))\n",
    "        lengths = (y_upper - y_lower)\n",
    "\n",
    "        if 'pearsons_correlation' + '_over_' + set_name not in results_dict:\n",
    "            results_dict['pearsons_correlation' + '_over_' + set_name] = []\n",
    "\n",
    "        results_dict['pearsons_correlation' + '_over_' + set_name] += [\n",
    "            stats.pearsonr(in_the_range, lengths)[0]]\n",
    "\n",
    "        if 'coverage' + '_over_' + set_name not in results_dict:\n",
    "            results_dict['coverage' + '_over_' + set_name] = []\n",
    "\n",
    "        results_dict['coverage' + '_over_' + set_name] += [np.mean(in_the_range)]\n",
    "\n",
    "        if 'interval_lengths' + '_over_' + set_name not in results_dict:\n",
    "            results_dict['interval_lengths' + '_over_' + set_name] = []\n",
    "\n",
    "        results_dict['interval_lengths' + '_over_' + set_name] += [np.mean(lengths)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0d887b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On dataset blog_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:0\n",
      "EP:200\n",
      "EP:400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:38<00:00, 158.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training ens at EP 547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Experiments.EXP1.trainer import model_callByName, loss_callByName\n",
    "\n",
    "POSSIBLE_REAL_DATA_NAMES = ['kin8nm', 'naval', 'meps_19', 'meps_20', 'meps_21', 'facebook_1', 'facebook_2',\n",
    "                            'blog_data', 'bio', 'scaled_bio', 'bike']\n",
    "\n",
    "\n",
    "# net train\n",
    "# ---------------------------------------------------------\n",
    "DATA_NAME = 'blog_data'\n",
    "\n",
    "\n",
    "\n",
    "data_type = REAL_DATA\n",
    "\n",
    "# DATA_NAMES = ['meps_19', 'meps_20', 'meps_21', 'facebook_1', 'facebook_2', 'blog_data']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SEEDS = range(0, 1)\n",
    "\n",
    "save_results_during_training = True\n",
    "\n",
    "\n",
    "arg_loss = 'batch_int'\n",
    "TRAINING_OVER_ALL_QUANTILES = True\n",
    "\n",
    "\n",
    "\n",
    "d = DATA_NAME\n",
    "\n",
    "print(\"On dataset \"+ d)\n",
    "\n",
    "for s in tqdm.tqdm(SEEDS):\n",
    "\n",
    "    arg_data = d\n",
    "    arg_seed = s\n",
    "\n",
    "\n",
    "    set_seeds(arg_seed)\n",
    "    data_args = Namespace(dataset=arg_data, seed=arg_seed)\n",
    "\n",
    "    # if data_type == REAL_DATA:\n",
    "    # Fetching data\n",
    "    data_out = get_scaled_data(arg_data, arg_seed, recal_prop = 0.1)\n",
    "\n",
    "    unscaled_x_train = None\n",
    "    unscaled_x_test = None\n",
    "    minority_group_uncertainty = None\n",
    "    group_feature = None\n",
    "\n",
    "\n",
    "    x_tr, x_va, x_te, y_tr, y_va, y_te, y_al = \\\n",
    "        data_out.x_tr, data_out.x_va, data_out.x_te, data_out.y_tr, \\\n",
    "        data_out.y_va, data_out.y_te, data_out.y_al\n",
    "    \n",
    "    # set aside some for recalibration\n",
    "    #############################################\n",
    "    x_recal = x_tr[:int(0.2 * len(x_tr))]\n",
    "    y_recal = y_tr[:int(0.2 * len(y_tr))]\n",
    "    x_tr = x_tr[int(0.2 * len(x_tr)):]\n",
    "    y_tr = y_tr[int(0.2 * len(y_tr)):]\n",
    "    #############################################\n",
    "\n",
    "    x_va, y_va = x_va.to(device), y_va.to(device)\n",
    "    x_tr, y_tr = x_tr.to(device), y_tr.to(device)\n",
    "    y_te, x_te = y_te.to(device), x_te.to(device)\n",
    "\n",
    "    x_test = x_te\n",
    "    y_test = y_te\n",
    "\n",
    "    w_tr, w_va, get_tr_weights = helper.get_wqr_weights(arg_loss, x_tr, y_tr, x_va, y_va, device = device)\n",
    "\n",
    "    y_range = (y_al.max() - y_al.min()).item()\n",
    "\n",
    "    # creating the model\n",
    "    num_tr = x_tr.shape[0]\n",
    "    dim_x = x_tr.shape[1]\n",
    "    dim_y = y_tr.shape[1]\n",
    "\n",
    "    model_ens = QModelEns(input_size=dim_x + 1, output_size=dim_y,\n",
    "                          hidden_size=64, num_layers=2, dropout=0,\n",
    "                          lr=1e-3, wd=0,\n",
    "                          num_ens=1, device=device)\n",
    "\n",
    "    loader = DataLoader(helper.IndexedDataset(x_tr, y_tr),\n",
    "                        shuffle=True,\n",
    "                        batch_size=1024)\n",
    "\n",
    "    # Loss function\n",
    "    loss_fn = get_loss_fn(arg_loss)\n",
    "    batch_loss = True if 'batch' in arg_loss else False\n",
    "    \"\"\" train loop \"\"\"\n",
    "    tr_loss_list = []\n",
    "    va_loss_list = []\n",
    "    te_loss_list = []\n",
    "    batch_size = 1024\n",
    "    for ep in range(2000):\n",
    "\n",
    "        if model_ens.done_training:\n",
    "            print('Done training ens at EP {}'.format(ep))\n",
    "            break\n",
    "\n",
    "        # Take train step\n",
    "        ep_train_loss = []  # list of losses from each batch, for one epoch\n",
    "        epoch_loss = []\n",
    "\n",
    "        for xi, yi, index in loader:\n",
    "            if TRAINING_OVER_ALL_QUANTILES:\n",
    "                q_list = torch.rand(30)\n",
    "            else:\n",
    "                q_list = torch.Tensor([alpha / 2])\n",
    "\n",
    "            arg_corr_mult = 0\n",
    "            loss = model_ens.loss(loss_fn, xi, yi, q_list,\n",
    "                                  batch_q=batch_loss,\n",
    "                                  take_step=True, args=arg_corr_mult, weights=get_tr_weights(index))\n",
    "            ep_train_loss.append(loss)\n",
    "\n",
    "        ep_tr_loss = np.nanmean(np.stack(ep_train_loss, axis=0), axis=0)\n",
    "        tr_loss_list.append(ep_tr_loss)\n",
    "\n",
    "\n",
    "\n",
    "        # Validation loss\n",
    "        # x_va, y_va = x_va.to(args.device), y_va.to(args.device)\n",
    "        if TRAINING_OVER_ALL_QUANTILES:\n",
    "            va_te_q_list = torch.linspace(0.01, 0.99, 99)\n",
    "        else:\n",
    "            va_te_q_list = torch.Tensor([alpha / 2, 1 - alpha / 2])\n",
    "\n",
    "        ep_va_loss = model_ens.update_va_loss(\n",
    "            loss_fn, x_va, y_va, va_te_q_list,\n",
    "            batch_q=batch_loss, curr_ep=ep, num_wait=200,\n",
    "            args=arg_corr_mult, weights=w_va\n",
    "        )\n",
    "        va_loss_list.append(ep_va_loss)\n",
    "\n",
    "        # Printing some losses\n",
    "        if (ep % 200 == 0):\n",
    "            print('EP:{}'.format(ep))\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    # Move everything to cpu\n",
    "    x_tr, y_tr, x_va, y_va, x_te, y_te = \\\n",
    "        x_tr.cpu(), y_tr.cpu(), x_va.cpu(), y_va.cpu(), x_te.cpu(), y_te.cpu()\n",
    "    model_ens.use_device(torch.device('cpu'))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f5f6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Experiments.EXP1.TestPerform import testPerform_projKernel\n",
    "from sklearn import random_projection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import torch\n",
    "from src.kernel_methods import kernel_estimator\n",
    "from losses import independence_penalty\n",
    "\n",
    "## \n",
    "\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "\n",
    "quantiles = torch.Tensor([alpha/2, 1-alpha/2])\n",
    "\n",
    "\n",
    "n_component = 50\n",
    "transformer = random_projection.GaussianRandomProjection(n_components = n_component)\n",
    "reformer = lambda x : torch.Tensor(transformer.fit_transform(x.cpu().numpy()))\n",
    "\n",
    "\n",
    "###############################################\n",
    "## might need to resample\n",
    "resample_recal = 4\n",
    "resample_test = 4\n",
    "\n",
    "x_recald = x_recal[:int(len(x_recal)/resample_recal)]\n",
    "y_recald = y_recal[:int(len(y_recal)/resample_recal)].view(-1).cuda()\n",
    "x_ted = x_te[:int(len(x_te)/resample_test)]\n",
    "y_ted = y_te[:int(len(y_te)/resample_test)].view(-1).cuda()\n",
    "\n",
    "###############################################\n",
    "\n",
    "recal_preds = model_ens.predict_q(\n",
    "    x_recald, quantiles, ens_pred_type='conf',\n",
    "    recal_model=None, recal_type=None\n",
    ")\n",
    "\n",
    "recal_preds = torch.permute(recal_preds, (1,0))\n",
    "recal_mean_1 = recal_preds[0].cuda()\n",
    "recal_mean_2 = recal_preds[1].cuda()\n",
    "\n",
    "\n",
    "test_preds = model_ens.predict_q(\n",
    "    x_ted, quantiles, ens_pred_type='conf',\n",
    "    recal_model=None, recal_type=None\n",
    ")\n",
    "\n",
    "test_preds = torch.permute(test_preds, (1,0))\n",
    "test_mean_1 = test_preds[0].cuda()\n",
    "test_mean_2 = test_preds[1].cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ab61414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'interval_AGCE': 0.7931297421455383}\n",
      "--------------------------------------------------\n",
      "5\n",
      "{'interval_AGCE': 0.07557249069213867}\n",
      "--------------------------------------------------\n",
      "10\n",
      "{'interval_AGCE': 0.023664116859436035}\n",
      "--------------------------------------------------\n",
      "15\n",
      "{'interval_AGCE': 0.052671730518341064}\n",
      "--------------------------------------------------\n",
      "30\n",
      "{'interval_AGCE': 0.038931310176849365}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ker_range = [1, 5, 10, 15, 30]\n",
    "for width in ker_range:\n",
    "    print(width)\n",
    "\n",
    "    # we do the recal mean for two quantiles \n",
    "\n",
    "\n",
    "    test_Z =  reformer(x_ted)\n",
    "\n",
    "    recal_Z = reformer(x_recald)\n",
    "\n",
    "\n",
    "    # lower part\n",
    "    eps_diffQuants_1 = kernel_estimator(\n",
    "        test_Z = test_Z.cuda(),\n",
    "        recal_Z = recal_Z.cuda(),\n",
    "        recal_epsilon = torch.Tensor(y_recald - recal_mean_1).cuda(),\n",
    "        quants = np.array([alpha/2]),\n",
    "        wid= width\n",
    "    )\n",
    "\n",
    "    y_lower = (eps_diffQuants_1 + test_mean_1.view(1,-1).repeat(len(eps_diffQuants_1),1)).cpu().numpy()\n",
    "\n",
    "    \n",
    "    # upper part\n",
    "    eps_diffQuants_2 = kernel_estimator(\n",
    "        test_Z = test_Z.cuda(),\n",
    "        recal_Z = recal_Z.cuda(),\n",
    "        recal_epsilon = torch.Tensor(y_recald - recal_mean_2).cuda(),\n",
    "        quants = np.array([1-alpha/2]),\n",
    "        wid= width\n",
    "    )\n",
    "\n",
    "    y_upper = (eps_diffQuants_2 + test_mean_2.view(1,-1).repeat(len(eps_diffQuants_2),1)).cpu().numpy()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ret = {}\n",
    "    val_criterias = [\n",
    "            \"interval_AGCE\"\n",
    "        ]  \n",
    "\n",
    "    for key in val_criterias:\n",
    "\n",
    "        real_loss = loss_callByName[key]\n",
    "\n",
    "        real_err = real_loss( torch.Tensor(np.vstack((y_lower, y_upper))), y_ted.cpu(), q_interval = np.array([alpha/2, 1-alpha/2])).item()\n",
    "\n",
    "        if isinstance(real_err, torch.Tensor):\n",
    "\n",
    "            real_err = real_err.item()\n",
    "\n",
    "        ret[key] = real_err\n",
    "\n",
    "\n",
    "    print(ret)\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949ff89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
