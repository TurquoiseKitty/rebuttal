{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc002888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: community\n",
      "Dimensions: train set (n=1595, p=100) ; test set (n=399, p=100)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "from Data_toCompare import CQR_datareader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 1\n",
    "\n",
    "random_state_train_test = seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "# desired miscoverage error\n",
    "alpha = 0.1\n",
    "\n",
    "# desired quanitile levels\n",
    "quantiles = [0.05, 0.95]\n",
    "\n",
    "# used to determine the size of test set\n",
    "test_ratio = 0.2\n",
    "\n",
    "# name of dataset\n",
    "dataset_base_path = \"./Data_toCompare/\"\n",
    "dataset_name = \"community\"\n",
    "\n",
    "# load the dataset\n",
    "X, y = CQR_datareader.GetDataset(dataset_name, dataset_base_path)\n",
    "\n",
    "# divide the dataset into test and train based on the test_ratio parameter\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=test_ratio,\n",
    "                                                    random_state=random_state_train_test)\n",
    "\n",
    "# reshape the data\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "# compute input dimensions\n",
    "n_train = x_train.shape[0]\n",
    "in_shape = x_train.shape[1]\n",
    "\n",
    "# display basic information\n",
    "print(\"Dataset: %s\" % (dataset_name))\n",
    "print(\"Dimensions: train set (n=%d, p=%d) ; test set (n=%d, p=%d)\" % \n",
    "      (x_train.shape[0], x_train.shape[1], x_test.shape[0], x_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1b618",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00b44650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into proper training set and calibration set\n",
    "idx = np.random.permutation(n_train)\n",
    "n_half = int(np.floor(n_train/2))\n",
    "idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n",
    "\n",
    "# zero mean and unit variance scaling \n",
    "scalerX = StandardScaler()\n",
    "scalerX = scalerX.fit(x_train[idx_train])\n",
    "\n",
    "# scale\n",
    "x_train = scalerX.transform(x_train)\n",
    "x_test = scalerX.transform(x_test)\n",
    "\n",
    "# scale the labels by dividing each by the mean absolute response\n",
    "mean_y_train = np.mean(np.abs(y_train[idx_train]))\n",
    "y_train = np.squeeze(y_train)/mean_y_train\n",
    "y_test = np.squeeze(y_test)/mean_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a447a0b2",
   "metadata": {},
   "source": [
    "# OurMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33c78f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'MACE_Loss': 0.01590702310204506, 'AGCE_Loss': 0.09994242340326309, 'CheckScore': 0.14681142568588257}\n",
      "Our Estimation: Percentage in the range (expecting 90.00): 88.220551\n",
      "Our Estimation: Average length: 1.713888\n",
      "6\n",
      "{'MACE_Loss': 0.031997524201869965, 'AGCE_Loss': 0.08201514929533005, 'CheckScore': 0.15161262452602386}\n",
      "Our Estimation: Percentage in the range (expecting 90.00): 87.719298\n",
      "Our Estimation: Average length: 1.709117\n",
      "7\n",
      "{'MACE_Loss': 0.020549040287733078, 'AGCE_Loss': 0.10552021116018295, 'CheckScore': 0.14577320218086243}\n",
      "Our Estimation: Percentage in the range (expecting 90.00): 86.716792\n",
      "Our Estimation: Average length: 1.717734\n",
      "8\n",
      "{'MACE_Loss': 0.020265376195311546, 'AGCE_Loss': 0.0823792889714241, 'CheckScore': 0.14947080612182617}\n",
      "Our Estimation: Percentage in the range (expecting 90.00): 85.714286\n",
      "Our Estimation: Average length: 1.751068\n",
      "9\n",
      "{'MACE_Loss': 0.022118112072348595, 'AGCE_Loss': 0.0871318057179451, 'CheckScore': 0.15051314234733582}\n",
      "Our Estimation: Percentage in the range (expecting 90.00): 88.471178\n",
      "Our Estimation: Average length: 1.779917\n",
      "10\n",
      "{'MACE_Loss': 0.0207779910415411, 'AGCE_Loss': 0.15569999814033508, 'CheckScore': 0.14691433310508728}\n",
      "Our Estimation: Percentage in the range (expecting 90.00): 89.724311\n",
      "Our Estimation: Average length: 1.811667\n"
     ]
    }
   ],
   "source": [
    "from cqr import helper\n",
    "from Experiments.EXP1.TestPerform import testPerform_projKernel\n",
    "from sklearn import random_projection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import torch\n",
    "from src.kernel_methods import kernel_estimator\n",
    "\n",
    "\n",
    "depth = 10\n",
    "\n",
    "train_X = x_train[idx_train]\n",
    "train_Y = y_train[idx_train]\n",
    "test_X = torch.Tensor(x_test)\n",
    "test_Y = torch.Tensor(y_test).view(-1).cuda()\n",
    "recal_X = torch.Tensor(x_train[idx_cal])\n",
    "recal_Y = torch.Tensor(y_train[idx_cal]).view(-1).cuda()\n",
    "\n",
    "rf_model = RandomForestRegressor(max_depth=depth, random_state=0)\n",
    "rf_model.fit(train_X, train_Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_component = 20\n",
    "transformer = random_projection.GaussianRandomProjection(n_components = n_component)\n",
    "reformer = lambda x : torch.Tensor(transformer.fit_transform(x.cpu().numpy()))\n",
    "\n",
    "for width in [5,6,7,8,9,10]:\n",
    "    print(width)\n",
    "    \n",
    "    record = testPerform_projKernel(\n",
    "        test_X, test_Y, recal_X, recal_Y, \n",
    "        model_name = \"RFKernel_RandomProj\", model= rf_model, reformer= reformer, wid = width) \n",
    "    \n",
    "    print(record)\n",
    "    \n",
    "    \n",
    "    \n",
    "    recal_mean = torch.Tensor(rf_model.predict(recal_X.cpu().numpy())).cuda()\n",
    "    test_mean = torch.Tensor(rf_model.predict(test_X.cpu().numpy())).cuda()\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_Z =  reformer(test_X)\n",
    "\n",
    "    recal_Z = reformer(recal_X)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    eps_diffQuants = kernel_estimator(\n",
    "        test_Z = test_Z.cuda(),\n",
    "        recal_Z = recal_Z.cuda(),\n",
    "        recal_epsilon = torch.Tensor(recal_Y - recal_mean).cuda(),\n",
    "        quants = np.array([0.05, 0.95]),\n",
    "        wid= width\n",
    "    )\n",
    "\n",
    "    y_diffQuants = (eps_diffQuants + test_mean.view(1,-1).repeat(len(eps_diffQuants),1)).cpu().numpy()\n",
    "\n",
    "    coverage_cp_qforest, length_cp_qforest = helper.compute_coverage(\n",
    "        test_Y.cpu().numpy(),\n",
    "        y_diffQuants[0], y_diffQuants[1], alpha, \"Our Estimation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaec074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
